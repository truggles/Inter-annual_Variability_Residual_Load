{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "Some files are missing entries\n",
    "* Empty rows are being added\n",
    "* 2003 is an especially bad year for gaps\n",
    "* Will use 2004-2019 for analysis\n",
    "* 2004 has many duplicate entries, they appear to follow the few % difference style of 2005\n",
    "\n",
    "# Daylight Savings Time\n",
    "Many files had the transition from EST to EDT and vice versa happening not at 2:00am, but later in the morning. I realigned this in the original files. This resolved some of the duplicate issues in the Spring time at 1:00am. In these cases, I took the first entry as chronologically first and shifted the duplicate to the next hour.\n",
    "\n",
    "# FIXME\n",
    "Some files have multiple entries for a single region for a given time stamp\n",
    "* The initiall processing prints these out for comparison. Many duplicates and gaps were resolved with DST correction mentioned above.\n",
    "\n",
    "Some files are missing entries\n",
    "* Missing values are filled with a linear interpolation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get UTC from local and DST\n",
    "def to_utc_dt(date_time, time_zone):\n",
    "    local = pytz.timezone ('US/Eastern')\n",
    "    naive = datetime.strptime(date_time, '%m/%d/%Y %H:%M:%S')\n",
    "    if time_zone == 'EST': # Eastern Standard Time\n",
    "        is_dst_now = False\n",
    "    if time_zone == 'EDT': # Eastern Daylight Time\n",
    "        is_dst_now = True\n",
    "    local_dt = local.localize(naive, is_dst=is_dst_now)\n",
    "    utc_dt = local_dt.astimezone(pytz.utc)\n",
    "\n",
    "    return utc_dt\n",
    "\n",
    "def get_files(year, month):\n",
    "    files = glob(f'./nyiso_{year}{month:02}/{year}*.csv')\n",
    "    files.sort()\n",
    "    dfs = []\n",
    "    for f in files:\n",
    "        if '_OLD' in f: # Saved files for reference\n",
    "            continue\n",
    "        #print(f)\n",
    "        df = nyiso_to_neat_data(f)\n",
    "        if type(df) == int:\n",
    "            continue\n",
    "        else:\n",
    "            dfs.append(df)\n",
    "    return dfs\n",
    "\n",
    "def nyiso_to_neat_data(fname):\n",
    "    df = pd.read_csv(fname)\n",
    "    #print(df.head())\n",
    "    #print(df.tail())\n",
    "    mapping = {}\n",
    "    mapping['date_time'] = []\n",
    "    mapping['old_date_time'] = []\n",
    "    mapping['time_zone'] = []\n",
    "    # Get all regions\n",
    "    # Some data issues lead to regions having multiple entries\n",
    "    # in first hour\n",
    "    start_time = -1\n",
    "    for idx in df.index:\n",
    "        utc_dt = to_utc_dt(df.loc[idx, 'Time Stamp'], df.loc[idx, 'Time Zone'])\n",
    "        if start_time == -1:\n",
    "            start_time = utc_dt\n",
    "        if utc_dt != start_time:\n",
    "            break\n",
    "        if df.loc[idx, 'Name'] not in mapping.keys():\n",
    "            mapping[df.loc[idx, 'Name']] = []\n",
    "    #print(mapping)\n",
    "    # Populate values\n",
    "    for idx in df.index:\n",
    "        utc_dt = to_utc_dt(df.loc[idx, 'Time Stamp'], df.loc[idx, 'Time Zone'])\n",
    "        if mapping['date_time'] == []:\n",
    "            mapping['date_time'].append(utc_dt)\n",
    "            mapping['old_date_time'].append(df.loc[idx, 'Time Stamp'])\n",
    "            mapping['time_zone'].append(df.loc[idx, 'Time Zone'])\n",
    "        if utc_dt != mapping['date_time'][-1]:\n",
    "            mapping['date_time'].append(utc_dt)\n",
    "            mapping['old_date_time'].append(df.loc[idx, 'Time Stamp'])\n",
    "            mapping['time_zone'].append(df.loc[idx, 'Time Zone'])\n",
    "        \n",
    "        # DUPLICATE ENTRIES\n",
    "        # Lots of duplicates in 2004 - seem to be order a few %, keep them like 2005\n",
    "        # The four cases in 2005 have ~ identical values, so avg them\n",
    "        # The three cases in 2006,2007,2008 have zero entries as one version, so take non-zero one\n",
    "        if len(mapping['date_time']) == len(mapping[df.loc[idx, 'Name']]):\n",
    "            #print(f\"Duplicate region entry for {df.loc[idx, 'Name']} at {df.loc[idx, 'Time Stamp']}\")\n",
    "            # if new values is zero, continue\n",
    "            if df.loc[idx, 'Integrated Load'] == 0:\n",
    "                print(f\" --- Duplicate with second value as zero {df.loc[idx, 'Name']}, skip\")\n",
    "            # if previous value was zero, replace\n",
    "            elif mapping[df.loc[idx, 'Name']][-1] == 0:\n",
    "                print(f\" --- Duplicate with initial value as zero, replace with {df.loc[idx, 'Integrated Load']}.\")\n",
    "                mapping[df.loc[idx, 'Name']][-1] = df.loc[idx, 'Integrated Load']\n",
    "            # else, avg them\n",
    "            else:\n",
    "                print(f\" --- Duplicate, averaging {mapping[df.loc[idx, 'Name']][-1]} with {df.loc[idx, 'Integrated Load']}.\")\n",
    "                print(f\" -------------------------------------------- {mapping[df.loc[idx, 'Name']][-1]} / {df.loc[idx, 'Integrated Load']} = {mapping[df.loc[idx, 'Name']][-1] / df.loc[idx, 'Integrated Load']}\")\n",
    "                mapping[df.loc[idx, 'Name']][-1] = (mapping[df.loc[idx, 'Name']][-1] + df.loc[idx, 'Integrated Load'])/2\n",
    "                   \n",
    "        if len(mapping['date_time']) == len(mapping[df.loc[idx, 'Name']]) + 1:\n",
    "            mapping[df.loc[idx, 'Name']].append(df.loc[idx, 'Integrated Load'])\n",
    "    #tgt_len = 24\n",
    "    if len(mapping['old_date_time']) != 24:\n",
    "        for i, date in enumerate(zip(mapping['old_date_time'], mapping['time_zone'], mapping['date_time'])):\n",
    "            print(i, date[0], date[1], date[2])\n",
    "    #for k, v in mapping.items():\n",
    "    #    print(k, len(v))\n",
    "    #    if len(v) != tgt_len:\n",
    "    #        print(f\"Length problem with file {fname}\")\n",
    "    #        print(k, len(v))\n",
    "    #        return -1\n",
    "    df_new = pd.DataFrame(mapping)\n",
    "    df_new = sum_ny_state(df_new)\n",
    "    return df_new\n",
    "\n",
    "def monthly_file(year, month):\n",
    "    dfs = get_files(year, month)\n",
    "    master = dfs[0]\n",
    "    for i in range(1, len(dfs)):\n",
    "        master = master.append(dfs[i], ignore_index = True)\n",
    "    #print(len(master.index))\n",
    "    master.to_csv(f'./nyiso_{year}{month:02}/demand_summary.csv', index=False)\n",
    "\n",
    "def sum_ny_state(df):\n",
    "    regions = df.columns.tolist()\n",
    "    regions.remove('date_time')\n",
    "    regions.remove('old_date_time')\n",
    "    regions.remove('time_zone')\n",
    "    ny_state = np.zeros(len(df.index))\n",
    "    for region in regions:\n",
    "        ny_state += df[region]\n",
    "    return_df = pd.DataFrame({\n",
    "        'date_time':df['date_time'],\n",
    "        'old_date_time':df['old_date_time'],\n",
    "        'time_zone':df['time_zone'],\n",
    "        'nyiso demand (MW)':ny_state\n",
    "    })\n",
    "    return return_df\n",
    "    \n",
    "def annual_file(year):\n",
    "    for month in range(1, 13):\n",
    "        df = pd.read_csv(f'./nyiso_{year}{month:02}/demand_summary.csv')\n",
    "        df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "        if month == 1:\n",
    "            master = df\n",
    "        else:\n",
    "            master = master.append(df, ignore_index = True)\n",
    "    \n",
    "    # Check for missing hours and insert them if needed\n",
    "    dt_to_add = []\n",
    "    start = master.iloc[0]['date_time']\n",
    "    prev = start\n",
    "    for idx in master.index:\n",
    "        crnt = master.loc[idx, 'date_time']\n",
    "        if crnt == start:\n",
    "            continue\n",
    "        # Check if sequential\n",
    "        if crnt != prev + timedelta(hours=1):\n",
    "            print(f\"Missing data between previous {prev} and idx {idx} dt {crnt}.  Adding an empty row.\")\n",
    "            dt_to_add.append(prev + timedelta(hours=1))\n",
    "            \n",
    "            # Add hours until gap is filled\n",
    "            if crnt != prev + timedelta(hours=2):\n",
    "                n_hours = 2\n",
    "                while True:\n",
    "                    if crnt != prev + timedelta(hours=n_hours):\n",
    "                        #print(f\"Need visual inspection for idx {idx} year {year}\")\n",
    "                        dt_to_add.append(prev + timedelta(hours=n_hours))\n",
    "                        n_hours += 1\n",
    "                    else:\n",
    "                        print(f\"Total gap length: {n_hours-1} around {crnt}\")\n",
    "                        break\n",
    "        prev = crnt\n",
    "    print(f\"dts to add: {dt_to_add}\")\n",
    "    to_add = {}\n",
    "    for col in master.columns:\n",
    "        if col == 'date_time':\n",
    "            to_add[col] = dt_to_add\n",
    "        else:\n",
    "            to_add[col] = [np.nan for _ in range(len(dt_to_add))]\n",
    "    master = master.append(pd.DataFrame(to_add), ignore_index = True)\n",
    "    master = master.sort_values(['date_time'], ascending = True)\n",
    "        \n",
    "    print(f\"Length for year {year}: {len(master.index)}\")\n",
    "    master.to_csv(f'./demand_summary_{year}.csv', index=False, na_rep='NA')\n",
    "\n",
    "                      \n",
    "\n",
    "                      \n",
    "# Full range of available data\n",
    "#for year in range(2002, 2020):\n",
    "\n",
    "# 2009 onwards has zero gaps (may have multiple entries for a single hour, will check)\n",
    "years = [2004, 2020]\n",
    "years = [2008, 2009]                      \n",
    "\n",
    "process = False\n",
    "if process:\n",
    "    for year in range(years[0], years[1]):\n",
    "        for month in range(1, 13):\n",
    "            print(year,month)\n",
    "            monthly_file(year, month)\n",
    "        annual_file(year)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_values(df, prev_filled, gap_length):\n",
    "    print(df.loc[prev_filled-1:prev_filled+gap_length+3])\n",
    "    prev_value = df.loc[prev_filled, 'nyiso demand (MW)']\n",
    "    following_value = df.loc[prev_filled+gap_length+1, 'nyiso demand (MW)']\n",
    "    #print(f\"Previous value at idx {prev_filled}, {prev_value}\")\n",
    "    #print(f\"Following value at idx {prev_filled+gap_length+1}, {following_value}\")\n",
    "    to_fill = [idx for idx in range(prev_filled+1, prev_filled+gap_length+1)]\n",
    "    print(f\"To Fill idx: {to_fill}\")\n",
    "    delta = (following_value - prev_value) / (gap_length + 1) # (gap_length + 1) b/c 1 missing hr, has two hour spacing\n",
    "    print(f\"Delta = {delta}\")\n",
    "    \n",
    "    for i, idx in enumerate(to_fill):\n",
    "        print(f\" --- idx {idx} = {df.loc[idx, 'nyiso demand (MW)']}\")\n",
    "        df.loc[idx, 'nyiso demand (MW)'] = prev_value + delta * (i+1)\n",
    "        print(f\" --- idx {idx} = {df.loc[idx, 'nyiso demand (MW)']}\")\n",
    "\n",
    "    \n",
    "\n",
    "def all_years(start_yr, end_yr):\n",
    "    for year in range(start_yr, end_yr):\n",
    "        df = pd.read_csv(f'./demand_summary_{year}.csv', na_values=\"0.0\")\n",
    "        df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "        if year == start_yr:\n",
    "            master = df\n",
    "        else:\n",
    "            master = master.append(df, ignore_index = True)\n",
    "    \n",
    "    # Gap Fill\n",
    "    prev_filled = master.index[0]\n",
    "    gap_length = 0\n",
    "    idxs = master.index\n",
    "    for idx in idxs:\n",
    "        # Is part of gap\n",
    "        if np.isnan(master.loc[idx, 'nyiso demand (MW)']):\n",
    "            gap_length += 1\n",
    "        # Is end of gap\n",
    "        elif gap_length > 0:\n",
    "            fill_values(master, prev_filled, gap_length)\n",
    "            prev_filled = idx\n",
    "            gap_length = 0\n",
    "        # Is normal admidst normal data\n",
    "        else:\n",
    "            prev_filled = idx\n",
    "    master.to_csv(f'./demand_summary_{start_yr}-{end_yr}.csv', index=False, na_rep='NA')        \n",
    "\n",
    "years = [2004, 2020]\n",
    "process = True\n",
    "if process:\n",
    "    all_years(years[0], years[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_MEM_compatible(start_yr, end_yr):\n",
    "    print(f\"In file: 'demand_summary_{start_yr}-{end_yr}.csv'\")\n",
    "    df = pd.read_csv(f'./demand_summary_{start_yr}-{end_yr}.csv')\n",
    "    df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "    \n",
    "    with open(f'NYISO_for_MEM_{start_yr}-{end_yr}.csv', 'w', newline='') as csvfile:\n",
    "\n",
    "        fieldnames = ['year', 'month', 'day', 'hour', 'demand (MW)']#,'date_time']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        for idx in df.index:\n",
    "            mem_format = df.loc[idx, 'date_time'] + timedelta(hours=-1)\n",
    "            writer.writerow({\n",
    "                'year': mem_format.year,\n",
    "                'month': mem_format.month,\n",
    "                'day': mem_format.day,\n",
    "                'hour': mem_format.hour+1,\n",
    "                'demand (MW)': df.loc[idx, 'nyiso demand (MW)'],\n",
    "                #'date_time': df.loc[idx, 'date_time']\n",
    "            })\n",
    "    print(f\"Outfile: 'NYISO_for_MEM_{start_yr}-{end_yr}.csv'\")\n",
    "\n",
    "years = [2004, 2020]\n",
    "process = True\n",
    "if process:\n",
    "    make_MEM_compatible(years[0], years[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
